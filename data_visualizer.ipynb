{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "from interpret import show\n",
    "from interpret.data import Marginal\n",
    "from interpret.glassbox import ExplainableBoostingRegressor, LinearRegression, RegressionTree\n",
    "from interpret.perf import RegressionPerf\n",
    "\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Create category called Region: country_province\n",
    "    region_list = [\"{}_{}\".format(df[\"Country_Region\"][i], df[\"Province_State\"][i]) for i in range(df.shape[0])]\n",
    "    df[\"Region\"]=region_list\n",
    "\n",
    "    # Get first day of corona virus for each region\n",
    "    unique_region_list = list(set(region_list))\n",
    "    unique_region_list.sort()\n",
    "    first_date_dict = {}\n",
    "    for region in unique_region_list:\n",
    "        mask = df[\"Region\"]==region\n",
    "        first_ix = np.where(df[mask][\"ConfirmedCases\"]>0)[0][0] -1    \n",
    "        first_date = df[mask][\"Date\"].iloc[first_ix]\n",
    "        first_date_dict[region] = first_date\n",
    "\n",
    "    # add column \"Days\": number of days since the first day of case per each region\n",
    "    def get_days(dt):\n",
    "        return dt.days\n",
    "    dummy = [first_date_dict[region] for region in df[\"Region\"]]\n",
    "    df[\"Days\"]=(pd.to_datetime(df['Date'])-pd.to_datetime(dummy)).apply(get_days)\n",
    "\n",
    "    # Add previous confirmed cases as a feature\n",
    "    loc_group=[\"Region\"]\n",
    "    df[\"prev_{}\".format('ConfirmedCases')] = df.groupby(loc_group)['ConfirmedCases'].shift()\n",
    "    df[\"prev_ConfirmedCases\"].fillna(0, inplace=True)\n",
    "    \n",
    "    # TODO\n",
    "    ### df = df[df[\"Days\"]>0].copy(deep=True)\n",
    "\n",
    "    # TODO use log\n",
    "    df[\"ConfirmedCases\"] = np.log1p(df[\"ConfirmedCases\"])\n",
    "    df[\"prev_ConfirmedCases\"] = np.log1p(df[\"prev_ConfirmedCases\"])\n",
    "\n",
    "    features = ['Days','Region',\"prev_ConfirmedCases\"]\n",
    "    # ConfirmCases, Fatilies\n",
    "    output_col = ['ConfirmedCases']\n",
    "    X = df[features]\n",
    "    # TODO use log1p\n",
    "    Y = df[output_col]\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y=preprocess(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(X,Y, unique_region_list,num_of_val_days):\n",
    "    \n",
    "    train_ix = []\n",
    "    val_ix = []\n",
    "    for region in unique_region_list:\n",
    "        \n",
    "        mask = X[\"Region\"]==region\n",
    "        ix = np.where(mask)[0]\n",
    "        \n",
    "        train_ix += list(ix[:-num_of_val_days].flatten())\n",
    "        val_ix += list(ix[-num_of_val_days:].flatten())\n",
    "        \n",
    "    return X.iloc[train_ix],X.iloc[val_ix],Y.iloc[train_ix],Y.iloc[val_ix]    \n",
    "\n",
    "# IMPORTANT NOTE: We can only use prev_ConfirmedCases for the first day to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "marginal = Marginal().explain_data(X, Y, name = 'Full train data')\n",
    "show(marginal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Predict with Explainable Boosting Machine (EBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT NOTE: assuming that X_features is sorted by number of days \"Days\"\n",
    "\n",
    "def evaluate_rmse(Y_predicted,Y_true):\n",
    "    return np.sqrt(mean_squared_error(Y_predicted,Y_true))\n",
    "\n",
    "def predict(X_features,Y,num_validation_days,num_days_to_predict):\n",
    "    unique_region_list = list(set(X_features[\"Region\"]))\n",
    "    unique_region_list.sort()\n",
    "    print(\"No of unique region list: {}\".format(len(unique_region_list)))\n",
    "    \n",
    "    # Split to train and validation\n",
    "    X_train,X_val,Y_train,Y_val = split_train_val(X,Y, unique_region_list,num_validation_days)\n",
    "    \n",
    "    # Train\n",
    "    model = ExplainableBoostingRegressor(random_state=seed)\n",
    "    model.fit(X_train,Y_train)\n",
    "    \n",
    "    # Predict for val\n",
    "    Y_val_predicted = np.zeros((X_val.shape[0],1))\n",
    "    \n",
    "    for i in range(X_val.shape[0]):\n",
    "        \n",
    "        if(i==0 or X_val.iloc[i-1][\"Region\"] != X_val.iloc[i][\"Region\"]):\n",
    "            pred = model.predict(X_val.iloc[[i]])[0]\n",
    "        else:\n",
    "            X_dummy  = X_val.iloc[[i]].copy(deep=True)\n",
    "            X_dummy[\"prev_ConfirmedCases\"] = pred\n",
    "            pred = model.predict(X_dummy)\n",
    "\n",
    "        Y_val_predicted[i] = pred\n",
    "        \n",
    "    # Report validation accuracy\n",
    "    val_rmse = evaluate_rmse(Y_val,Y_val_predicted)\n",
    "    ###############################################################################\n",
    "    # Train with full data\n",
    "    model_full = ExplainableBoostingRegressor(random_state=seed)\n",
    "    model_full.fit(X_features,Y)\n",
    "    \n",
    "    \n",
    "    # Predict for test\n",
    "    Y_test_predicted = np.zeros((len(unique_region_list)*num_days_to_predict,1))\n",
    "    count=0\n",
    "    for region in unique_region_list:\n",
    "        mask = X_features[\"Region\"]==region\n",
    "        \n",
    "        prev_ConfirmedCase_ = Y[mask][\"ConfirmedCases\"].iloc[-1]\n",
    "        #print(prev_ConfirmedCase_,np.exp(prev_ConfirmedCase_)-1)\n",
    "        \n",
    "        X_dummy = X[mask].iloc[[-1]].copy(deep=True)\n",
    "        X_dummy[\"prev_ConfirmedCases\"] = prev_ConfirmedCase_\n",
    "        X_dummy[\"Days\"] = X_dummy[\"Days\"]+1\n",
    "        \n",
    "        pred = model_full.predict(X_dummy)\n",
    "        Y_test_predicted[count] = pred\n",
    "        count = count+1\n",
    "        \n",
    "        for days_ahead in range(2,num_days_to_predict+1):\n",
    "            \n",
    "            X_dummy[\"prev_ConfirmedCases\"] = pred\n",
    "            X_dummy[\"Days\"] = X_dummy[\"Days\"]+1\n",
    "            pred = model_full.predict(X_dummy)\n",
    "            Y_test_predicted[count] = pred\n",
    "            \n",
    "            count = count+1\n",
    "      \n",
    "    assert count==len(Y_test_predicted), \"Something wrong\"\n",
    "    \n",
    "\n",
    "    return unique_region_list,Y_val,Y_val_predicted,val_rmse,Y_test_predicted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unique_region_list,Y_val,Y_val_predicted,val_rmse,Y_test_predicted=predict(X,Y,10,43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation error\n",
    "print(val_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the final value\n",
    "Y_test_predicted_final = np.exp(Y_test_predicted)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_test_predicted_final)\n",
    "print(\"*****\")\n",
    "print(len(Y_test_predicted_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DUMP PLAYGROUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_region_list(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Create category called Region: country_province\n",
    "    region_list = [\"{}_{}\".format(df[\"Country_Region\"][i], df[\"Province_State\"][i]) for i in range(df.shape[0])]\n",
    "    df[\"Region\"]=region_list\n",
    "\n",
    "    # Get first day of corona virus for each region\n",
    "    unique_region_list = list(set(region_list))\n",
    "    unique_region_list.sort()\n",
    "    \n",
    "    num_list = [np.sum(np.array(region_list)==region) for region in unique_region_list]\n",
    "    return np.array(unique_region_list),np.array(num_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
